{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71fdcb23",
   "metadata": {},
   "source": [
    "# nnU-Net v2 (KSSD2025) — Hugging Face Space Notebook\n",
    "\n",
    "This notebook is structured for **Hugging Face Spaces (JupyterLab)**.\n",
    "It:\n",
    "1) Downloads the dataset from a Hugging Face dataset repo  \n",
    "2) Converts TIFF → NIfTI (.nii.gz)  \n",
    "3) Builds `nnUNet_raw/Dataset501_KSSD`  \n",
    "4) Runs `plan_and_preprocess`  \n",
    "5) Trains a selected fold\n",
    "\n",
    "> **Tip:** For Spaces, enable **Persistent Storage** so `/data` keeps your preprocessing + checkpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 1 — Install deps\n",
    "# =========================\n",
    "!pip -q install nnunetv2 nibabel SimpleITK acvl-utils tifffile huggingface_hub\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1877614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 2 — Paths + download dataset\n",
    "# =========================\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Persistent storage path in HF Spaces (recommended)\n",
    "BASE = Path(\"/data/nnunet_kssd\").resolve()\n",
    "BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATASET_REPO = \"thecodex/KSSD2025KidneyStoneSegmentationDataset\"  # change if your repo differs\n",
    "LOCAL_DATA = BASE / \"kssd_raw_download\"\n",
    "\n",
    "# Downloads the dataset repo files into LOCAL_DATA\n",
    "snapshot_download(\n",
    "    repo_id=DATASET_REPO,\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=str(LOCAL_DATA),\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n",
    "\n",
    "print(\"Downloaded to:\", LOCAL_DATA)\n",
    "print(\"Top-level items:\", [p.name for p in LOCAL_DATA.iterdir()][:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 3 — Build nnU-Net dataset (TIFF → NIfTI)\n",
    "# =========================\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import nibabel as nib\n",
    "import shutil\n",
    "\n",
    "# nnU-Net folder roots (inside persistent storage)\n",
    "nnUNet_raw = BASE / \"nnUNet_raw\"\n",
    "nnUNet_preprocessed = BASE / \"nnUNet_preprocessed\"\n",
    "nnUNet_results = BASE / \"nnUNet_results\"\n",
    "\n",
    "os.environ[\"nnUNet_raw\"] = str(nnUNet_raw)\n",
    "os.environ[\"nnUNet_preprocessed\"] = str(nnUNet_preprocessed)\n",
    "os.environ[\"nnUNet_results\"] = str(nnUNet_results)\n",
    "\n",
    "dataset_id = 501\n",
    "dataset_name = \"Dataset501_KSSD\"\n",
    "dataset_dir = nnUNet_raw / dataset_name\n",
    "imagesTr = dataset_dir / \"imagesTr\"\n",
    "labelsTr = dataset_dir / \"labelsTr\"\n",
    "\n",
    "# Clean + recreate dataset folder\n",
    "if dataset_dir.exists():\n",
    "    shutil.rmtree(dataset_dir)\n",
    "imagesTr.mkdir(parents=True, exist_ok=True)\n",
    "labelsTr.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Locate TIFF folders inside the downloaded dataset\n",
    "# Expected: .../image/*.tif and .../label/*.tif (adjust if your repo layout differs)\n",
    "img_tifs = sorted(LOCAL_DATA.rglob(\"image/*.tif\"))\n",
    "lbl_tifs = sorted(LOCAL_DATA.rglob(\"label/*.tif\"))\n",
    "\n",
    "assert len(img_tifs) > 0, \"No image TIFFs found under **image/*.tif**. Check your dataset repo layout.\"\n",
    "assert len(lbl_tifs) > 0, \"No label TIFFs found under **label/*.tif**. Check your dataset repo layout.\"\n",
    "assert len(img_tifs) == len(lbl_tifs), f\"Image/label count mismatch: {len(img_tifs)} vs {len(lbl_tifs)}\"\n",
    "\n",
    "print(f\"Found {len(img_tifs)} image TIFFs and {len(lbl_tifs)} label TIFFs\")\n",
    "\n",
    "# Convert each 2D TIFF slice to a 3D NIfTI volume with a singleton Z dim (H,W,1)\n",
    "# nnU-Net expects:\n",
    "#  - imagesTr: case_xxxx_0000.nii.gz\n",
    "#  - labelsTr: case_xxxx.nii.gz\n",
    "for idx, (it, lt) in enumerate(zip(img_tifs, lbl_tifs), start=1):\n",
    "    case_id = f\"case_{idx:04d}\"\n",
    "\n",
    "    img = tifffile.imread(it)\n",
    "    if img.ndim == 2:\n",
    "        img = img[:, :, np.newaxis]\n",
    "    if img.dtype not in (np.float32, np.int16, np.uint16, np.int32):\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "    lbl = tifffile.imread(lt)\n",
    "    if lbl.ndim == 2:\n",
    "        lbl = lbl[:, :, np.newaxis]\n",
    "    # binarize labels (0/1)\n",
    "    lbl = (lbl > 0).astype(np.uint8)\n",
    "\n",
    "    nib.save(nib.Nifti1Image(img, affine=np.eye(4)), imagesTr / f\"{case_id}_0000.nii.gz\")\n",
    "    nib.save(nib.Nifti1Image(lbl, affine=np.eye(4)), labelsTr / f\"{case_id}.nii.gz\")\n",
    "\n",
    "print(\"Done. Example files:\")\n",
    "print(\"imagesTr:\", sorted([p.name for p in imagesTr.glob('*.nii.gz')])[:3])\n",
    "print(\"labelsTr:\", sorted([p.name for p in labelsTr.glob('*.nii.gz')])[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee3c41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 4 — dataset.json\n",
    "# =========================\n",
    "import json\n",
    "\n",
    "dataset_json = {\n",
    "    \"channel_names\": {\"0\": \"CT\"},\n",
    "    \"labels\": {\"background\": 0, \"stone\": 1},\n",
    "    \"numTraining\": len(list(imagesTr.glob(\"*.nii.gz\"))),\n",
    "    \"file_ending\": \".nii.gz\",\n",
    "}\n",
    "(dataset_dir / \"dataset.json\").write_text(json.dumps(dataset_json, indent=2))\n",
    "print(\"Wrote:\", dataset_dir / \"dataset.json\")\n",
    "print((dataset_dir / \"dataset.json\").read_text()[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c828b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 5 — Plan + preprocess\n",
    "# =========================\n",
    "!nnUNetv2_plan_and_preprocess -d 501 --verify_dataset_integrity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da075ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 6 — Train (choose fold)\n",
    "# =========================\n",
    "FOLD = 0   # set 0..4\n",
    "CONFIG = \"2d\"\n",
    "\n",
    "!nnUNetv2_train 501 {CONFIG} {FOLD}\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
